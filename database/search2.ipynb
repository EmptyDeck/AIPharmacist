{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b0380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING AND ANALYZING DRUG DATASETS\n",
      "================================================================================\n",
      "âœ“ Loaded high_confidence.csv: 663 rows, 2 columns\n",
      "âœ“ Loaded product_adverse_effect.csv: 28126418 rows, 7 columns\n",
      "âœ“ Loaded product_label.csv: 59515 rows, 5 columns\n",
      "âœ“ Loaded product_to_rxnorm.csv: 94608 rows, 2 columns\n",
      "âœ“ Loaded vocab_meddra_adverse_effect.csv: 7177 rows, 3 columns\n",
      "âœ“ Loaded vocab_rxnorm_ingredient.csv: 2562 rows, 3 columns\n",
      "âœ“ Loaded vocab_rxnorm_ingredient_to_product.csv: 11590 rows, 2 columns\n",
      "âœ“ Loaded vocab_rxnorm_product.csv: 18594 rows, 3 columns\n",
      "\n",
      "================================================================================\n",
      "DATASET STRUCTURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š HIGH_CONFIDENCE.CSV\n",
      "------------------------------------------------------------\n",
      "Shape: (663, 2)\n",
      "Columns: ['ingredient_id', 'effect_meddra_id']\n",
      "Data types:\n",
      "ingredient_id       int64\n",
      "effect_meddra_id    int64\n",
      "dtype: object\n",
      "No missing values\n",
      "Sample data:\n",
      "   ingredient_id  effect_meddra_id\n",
      "0          68149          10037844\n",
      "1           6851          10024382\n",
      "2          10395          10019211\n",
      "\n",
      "\n",
      "ðŸ“Š PRODUCT_ADVERSE_EFFECT.CSV\n",
      "------------------------------------------------------------\n",
      "Shape: (28126418, 7)\n",
      "Columns: ['product_label_id', 'effect_id', 'label_section', 'effect_meddra_id', 'match_method', 'pred0', 'pred1']\n",
      "Data types:\n",
      "product_label_id      int64\n",
      "effect_id             int64\n",
      "label_section        object\n",
      "effect_meddra_id      int64\n",
      "match_method         object\n",
      "pred0               float64\n",
      "pred1               float64\n",
      "dtype: object\n",
      "Missing values:\n",
      "label_section    1316089\n",
      "pred0             544756\n",
      "pred1             544756\n",
      "dtype: int64\n",
      "Sample data:\n",
      "   product_label_id  effect_id label_section  effect_meddra_id match_method  pred0  pred1\n",
      "0               270          1           NaN          10050659           SM    NaN    NaN\n",
      "1               270          2           NaN          10042128           SM    NaN    NaN\n",
      "2               270          3           NaN          10013781           SM    NaN    NaN\n",
      "\n",
      "\n",
      "ðŸ“Š PRODUCT_LABEL.CSV\n",
      "------------------------------------------------------------\n",
      "Shape: (59515, 5)\n",
      "Columns: ['label_id', 'source', 'source_product_name', 'source_product_id', 'source_label_url']\n",
      "Data types:\n",
      "label_id                int64\n",
      "source                 object\n",
      "source_product_name    object\n",
      "source_product_id      object\n",
      "source_label_url       object\n",
      "dtype: object\n",
      "No missing values\n",
      "Sample data:\n",
      "   label_id source                                 source_product_name source_product_id                                               source_label_url\n",
      "0         1     JP                                      ãƒ–ã‚¤ãƒ•ã‚§ãƒ³ãƒ‰200mgé™æ³¨ç”¨          00050557  https://www.kegg.jp/medicus-bin/japic_med?japic_code=00050557\n",
      "1         2     JP  ãƒ”ã‚ªã‚°ãƒªã‚¿ã‚¾ãƒ³éŒ 15mgã€Œæ­¦ç”°ãƒ†ãƒã€ (å¾Œç™ºå“)\\nãƒ”ã‚ªã‚°ãƒªã‚¿ã‚¾ãƒ³éŒ 30mgã€Œæ­¦ç”°ãƒ†ãƒã€ (å¾Œç™ºå“)          00068619  https://www.kegg.jp/medicus-bin/japic_med?japic_code=00068619\n",
      "2         3     JP  ã‚¸ãƒ«ãƒã‚¢ã‚¼ãƒ å¡©é…¸å¡©éŒ 30mgã€ŒCHã€ (å¾Œç™ºå“)\\nã‚¸ãƒ«ãƒã‚¢ã‚¼ãƒ å¡©é…¸å¡©éŒ 60mgã€ŒCHã€ (å¾Œç™ºå“)          00059622  https://www.kegg.jp/medicus-bin/japic_med?japic_code=00059622\n",
      "\n",
      "\n",
      "ðŸ“Š PRODUCT_TO_RXNORM.CSV\n",
      "------------------------------------------------------------\n",
      "Shape: (94608, 2)\n",
      "Columns: ['label_id', 'rxnorm_product_id']\n",
      "Data types:\n",
      "label_id              int64\n",
      "rxnorm_product_id    object\n",
      "dtype: object\n",
      "No missing values\n",
      "Sample data:\n",
      "   label_id rxnorm_product_id\n",
      "0      3794            213729\n",
      "1      2017            404408\n",
      "2      2019            309076\n",
      "\n",
      "\n",
      "ðŸ“Š VOCAB_MEDDRA_ADVERSE_EFFECT.CSV\n",
      "------------------------------------------------------------\n",
      "Shape: (7177, 3)\n",
      "Columns: ['meddra_id', 'meddra_name', 'meddra_term_type']\n",
      "Data types:\n",
      "meddra_id            int64\n",
      "meddra_name         object\n",
      "meddra_term_type    object\n",
      "dtype: object\n",
      "No missing values\n",
      "Sample data:\n",
      "   meddra_id                meddra_name meddra_term_type\n",
      "0   10000021  21-hydroxylase deficiency               PT\n",
      "1   10000045           Abdomen enlarged              LLT\n",
      "2   10000050        Abdominal adhesions               PT\n",
      "\n",
      "\n",
      "ðŸ“Š VOCAB_RXNORM_INGREDIENT.CSV\n",
      "------------------------------------------------------------\n",
      "Shape: (2562, 3)\n",
      "Columns: ['rxnorm_id', 'rxnorm_name', 'rxnorm_term_type']\n",
      "Data types:\n",
      "rxnorm_id           object\n",
      "rxnorm_name         object\n",
      "rxnorm_term_type    object\n",
      "dtype: object\n",
      "No missing values\n",
      "Sample data:\n",
      "  rxnorm_id                                      rxnorm_name rxnorm_term_type\n",
      "0   1006297  Aspergillus niger var. niger allergenic extract       Ingredient\n",
      "1     10814                                     liothyronine       Ingredient\n",
      "2     10829                                     trimethoprim       Ingredient\n",
      "\n",
      "\n",
      "ðŸ“Š VOCAB_RXNORM_INGREDIENT_TO_PRODUCT.CSV\n",
      "------------------------------------------------------------\n",
      "Shape: (11590, 2)\n",
      "Columns: ['product_id', 'ingredient_id']\n",
      "Data types:\n",
      "product_id       object\n",
      "ingredient_id    object\n",
      "dtype: object\n",
      "No missing values\n",
      "Sample data:\n",
      "  product_id ingredient_id\n",
      "0     573193         10600\n",
      "1     574983        283742\n",
      "2     861636         10600\n",
      "\n",
      "\n",
      "ðŸ“Š VOCAB_RXNORM_PRODUCT.CSV\n",
      "------------------------------------------------------------\n",
      "Shape: (18594, 3)\n",
      "Columns: ['rxnorm_id', 'rxnorm_name', 'rxnorm_term_type']\n",
      "Data types:\n",
      "rxnorm_id           object\n",
      "rxnorm_name         object\n",
      "rxnorm_term_type    object\n",
      "dtype: object\n",
      "No missing values\n",
      "Sample data:\n",
      "     rxnorm_id                                       rxnorm_name rxnorm_term_type\n",
      "0  OMOP5040582                                          Zercepac       Brand Name\n",
      "1  OMOP5040599                                          Nustendi       Brand Name\n",
      "2      1655928  ivacaftor 125 MG / lumacaftor 200 MG Oral Tablet              SCD\n",
      "\n",
      "\n",
      "================================================================================\n",
      "KEY COLUMN IDENTIFICATION\n",
      "================================================================================\n",
      "\n",
      "ðŸ”‘ high_confidence.csv:\n",
      "  - ingredient_id: 71 unique values (0.107 ratio)\n",
      "    Sample: [68149, 6851, 10395, 1100072, 5487]\n",
      "  - effect_meddra_id: 180 unique values (0.271 ratio)\n",
      "    Sample: [10037844, 10024382, 10019211, 10017076, 10008479]\n",
      "\n",
      "ðŸ”‘ product_adverse_effect.csv:\n",
      "  - product_label_id: 59515 unique values (0.002 ratio)\n",
      "    Sample: [270, 270, 270, 270, 270]\n",
      "  - effect_id: 28126418 unique values (1.0 ratio)\n",
      "    Sample: [1, 2, 3, 4, 5]\n",
      "  - effect_meddra_id: 9079 unique values (0.0 ratio)\n",
      "    Sample: [10050659, 10042128, 10013781, 10018388, 10054792]\n",
      "\n",
      "ðŸ”‘ product_label.csv:\n",
      "  - label_id: 59515 unique values (1.0 ratio)\n",
      "    Sample: [1, 2, 3, 4, 5]\n",
      "  - source_product_name: 44009 unique values (0.739 ratio)\n",
      "    Sample: ['ãƒ–ã‚¤ãƒ•ã‚§ãƒ³ãƒ‰200mgé™æ³¨ç”¨', 'ãƒ”ã‚ªã‚°ãƒªã‚¿ã‚¾ãƒ³éŒ 15mgã€Œæ­¦ç”°ãƒ†ãƒã€ (å¾Œç™ºå“)\\nãƒ”ã‚ªã‚°ãƒªã‚¿ã‚¾ãƒ³éŒ 30mgã€Œæ­¦ç”°ãƒ†ãƒã€ (å¾Œç™ºå“)', 'ã‚¸ãƒ«ãƒã‚¢ã‚¼ãƒ å¡©é…¸å¡©éŒ 30mgã€ŒCHã€ (å¾Œç™ºå“)\\nã‚¸ãƒ«ãƒã‚¢ã‚¼ãƒ å¡©é…¸å¡©éŒ 60mgã€ŒCHã€ (å¾Œç™ºå“)', 'ã‚¸ãƒ«ãƒã‚¢ã‚¼ãƒ å¡©é…¸å¡©é™æ³¨ç”¨250mgã€Œæ—¥åŒ»å·¥ã€ (å¾Œç™ºå“)', 'ã‚»ãƒ«ãƒˆãƒ©ãƒªãƒ³éŒ 25mgã€Œææž—ã€ (å¾Œç™ºå“)\\nã‚»ãƒ«ãƒˆãƒ©ãƒªãƒ³éŒ 50mgã€Œææž—ã€ (å¾Œç™ºå“)\\nã‚»ãƒ«ãƒˆãƒ©ãƒªãƒ³éŒ 100mgã€Œææž—ã€ (å¾Œç™ºå“)']\n",
      "  - source_product_id: 59515 unique values (1.0 ratio)\n",
      "    Sample: ['00050557', '00068619', '00059622', '00066950', '00070747']\n",
      "\n",
      "ðŸ”‘ product_to_rxnorm.csv:\n",
      "  - label_id: 59121 unique values (0.625 ratio)\n",
      "    Sample: [3794, 2017, 2019, 739, 3262]\n",
      "  - rxnorm_product_id: 19513 unique values (0.206 ratio)\n",
      "    Sample: ['213729', '404408', '309076', '313090', '1149663']\n",
      "\n",
      "ðŸ”‘ vocab_meddra_adverse_effect.csv:\n",
      "  - meddra_id: 7177 unique values (1.0 ratio)\n",
      "    Sample: [10000021, 10000045, 10000050, 10000054, 10000055]\n",
      "  - meddra_name: 7177 unique values (1.0 ratio)\n",
      "    Sample: ['21-hydroxylase deficiency', 'Abdomen enlarged', 'Abdominal adhesions', 'Abdominal aortic aneurysm', 'Abdominal colic']\n",
      "  - meddra_term_type: 2 unique values (0.0 ratio)\n",
      "    Sample: ['PT', 'LLT', 'PT', 'LLT', 'LLT']\n",
      "\n",
      "ðŸ”‘ vocab_rxnorm_ingredient.csv:\n",
      "  - rxnorm_id: 2562 unique values (1.0 ratio)\n",
      "    Sample: ['1006297', '10814', '10829', '108542', '10869']\n",
      "  - rxnorm_name: 2562 unique values (1.0 ratio)\n",
      "    Sample: ['Aspergillus niger var. niger allergenic extract', 'liothyronine', 'trimethoprim', 'Meningitis vaccine', 'tropicamide']\n",
      "  - rxnorm_term_type: 1 unique values (0.0 ratio)\n",
      "    Sample: ['Ingredient', 'Ingredient', 'Ingredient', 'Ingredient', 'Ingredient']\n",
      "\n",
      "ðŸ”‘ vocab_rxnorm_ingredient_to_product.csv:\n",
      "  - product_id: 9089 unique values (0.784 ratio)\n",
      "    Sample: ['573193', '574983', '861636', '404786', '2557234']\n",
      "  - ingredient_id: 2562 unique values (0.221 ratio)\n",
      "    Sample: ['10600', '283742', '10600', '2019', '2465242']\n",
      "\n",
      "ðŸ”‘ vocab_rxnorm_product.csv:\n",
      "  - rxnorm_id: 18594 unique values (1.0 ratio)\n",
      "    Sample: ['OMOP5040582', 'OMOP5040599', '1655928', '1745280', '197785']\n",
      "  - rxnorm_name: 18594 unique values (1.0 ratio)\n",
      "    Sample: ['Zercepac', 'Nustendi', 'ivacaftor 125 MG / lumacaftor 200 MG Oral Tablet', 'norepinephrine 1 MG/ML Injection', 'hydrocortisone 2.5 % Topical Lotion']\n",
      "  - rxnorm_term_type: 27 unique values (0.001 ratio)\n",
      "    Sample: ['Brand Name', 'Brand Name', 'SCD', 'SCD', 'PSN']\n",
      "\n",
      "================================================================================\n",
      "RELATIONSHIP ANALYSIS\n",
      "================================================================================\n",
      "ðŸ”— COMMON COLUMNS BETWEEN DATASETS:\n",
      "  high_confidence.csv â†” product_adverse_effect.csv: ['effect_meddra_id']\n",
      "  high_confidence.csv â†” vocab_rxnorm_ingredient_to_product.csv: ['ingredient_id']\n",
      "  product_adverse_effect.csv â†” high_confidence.csv: ['effect_meddra_id']\n",
      "  product_label.csv â†” product_to_rxnorm.csv: ['label_id']\n",
      "  product_to_rxnorm.csv â†” product_label.csv: ['label_id']\n",
      "  vocab_rxnorm_ingredient.csv â†” vocab_rxnorm_product.csv: ['rxnorm_name', 'rxnorm_id', 'rxnorm_term_type']\n",
      "  vocab_rxnorm_ingredient_to_product.csv â†” high_confidence.csv: ['ingredient_id']\n",
      "  vocab_rxnorm_product.csv â†” vocab_rxnorm_ingredient.csv: ['rxnorm_name', 'rxnorm_id', 'rxnorm_term_type']\n",
      "\n",
      "ðŸ”— POTENTIAL FOREIGN KEY RELATIONSHIPS:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DrugDatasetExplorer:\n",
    "    def __init__(self):\n",
    "        self.datasets = {}\n",
    "        self.file_names = [\n",
    "            'high_confidence.csv',\n",
    "            'product_adverse_effect.csv', \n",
    "            'product_label.csv',\n",
    "            'product_to_rxnorm.csv',\n",
    "            'vocab_meddra_adverse_effect.csv',\n",
    "            'vocab_rxnorm_ingredient.csv',\n",
    "            'vocab_rxnorm_ingredient_to_product.csv',\n",
    "            'vocab_rxnorm_product.csv'\n",
    "        ]\n",
    "    \n",
    "    def load_datasets(self):\n",
    "        \"\"\"Load all CSV files and store basic info\"\"\"\n",
    "        print(\"=\"*80)\n",
    "        print(\"LOADING AND ANALYZING DRUG DATASETS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for file_name in self.file_names:\n",
    "            try:\n",
    "                df = pd.read_csv(file_name)\n",
    "                self.datasets[file_name] = df\n",
    "                print(f\"âœ“ Loaded {file_name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"âœ— File not found: {file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âœ— Error loading {file_name}: {str(e)}\")\n",
    "    \n",
    "    def analyze_dataset_structure(self):\n",
    "        \"\"\"Analyze the structure of each dataset\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DATASET STRUCTURE ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for file_name, df in self.datasets.items():\n",
    "            print(f\"\\nðŸ“Š {file_name.upper()}\")\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            print(f\"Columns: {list(df.columns)}\")\n",
    "            print(f\"Data types:\\n{df.dtypes}\")\n",
    "            \n",
    "            # Check for missing values\n",
    "            missing = df.isnull().sum()\n",
    "            if missing.sum() > 0:\n",
    "                print(f\"Missing values:\\n{missing[missing > 0]}\")\n",
    "            else:\n",
    "                print(\"No missing values\")\n",
    "            \n",
    "            # Show sample data\n",
    "            print(\"Sample data:\")\n",
    "            print(df.head(3).to_string())\n",
    "            print()\n",
    "    \n",
    "    def identify_key_columns(self):\n",
    "        \"\"\"Identify potential key columns for joining datasets\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"KEY COLUMN IDENTIFICATION\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Common patterns for key columns\n",
    "        key_patterns = ['id', 'code', 'rxnorm', 'meddra', 'product', 'ingredient', 'cui']\n",
    "        \n",
    "        potential_keys = {}\n",
    "        \n",
    "        for file_name, df in self.datasets.items():\n",
    "            keys = []\n",
    "            for col in df.columns:\n",
    "                col_lower = col.lower()\n",
    "                if any(pattern in col_lower for pattern in key_patterns):\n",
    "                    unique_count = df[col].nunique()\n",
    "                    total_count = len(df)\n",
    "                    uniqueness_ratio = unique_count / total_count\n",
    "                    keys.append({\n",
    "                        'column': col,\n",
    "                        'unique_values': unique_count,\n",
    "                        'total_rows': total_count,\n",
    "                        'uniqueness_ratio': round(uniqueness_ratio, 3),\n",
    "                        'sample_values': df[col].dropna().head(5).tolist()\n",
    "                    })\n",
    "            \n",
    "            potential_keys[file_name] = keys\n",
    "            \n",
    "            print(f\"\\nðŸ”‘ {file_name}:\")\n",
    "            if keys:\n",
    "                for key_info in keys:\n",
    "                    print(f\"  - {key_info['column']}: {key_info['unique_values']} unique values \"\n",
    "                          f\"({key_info['uniqueness_ratio']} ratio)\")\n",
    "                    print(f\"    Sample: {key_info['sample_values']}\")\n",
    "            else:\n",
    "                print(\"  No obvious key columns found\")\n",
    "    \n",
    "    def analyze_relationships(self):\n",
    "        \"\"\"Analyze potential relationships between datasets\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RELATIONSHIP ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Extract all column names and look for common patterns\n",
    "        all_columns = {}\n",
    "        for file_name, df in self.datasets.items():\n",
    "            all_columns[file_name] = df.columns.tolist()\n",
    "        \n",
    "        # Find common column names or patterns\n",
    "        column_similarities = {}\n",
    "        for file1, cols1 in all_columns.items():\n",
    "            for file2, cols2 in all_columns.items():\n",
    "                if file1 != file2:\n",
    "                    common_cols = set(cols1) & set(cols2)\n",
    "                    if common_cols:\n",
    "                        key = f\"{file1} â†” {file2}\"\n",
    "                        column_similarities[key] = list(common_cols)\n",
    "        \n",
    "        print(\"ðŸ”— COMMON COLUMNS BETWEEN DATASETS:\")\n",
    "        if column_similarities:\n",
    "            for relationship, common_cols in column_similarities.items():\n",
    "                print(f\"  {relationship}: {common_cols}\")\n",
    "        else:\n",
    "            print(\"  No exact column name matches found\")\n",
    "        \n",
    "        # Look for potential foreign key relationships\n",
    "        print(\"\\nðŸ”— POTENTIAL FOREIGN KEY RELATIONSHIPS:\")\n",
    "        self._analyze_foreign_keys()\n",
    "    \n",
    "    def _analyze_foreign_keys(self):\n",
    "        \"\"\"Analyze potential foreign key relationships\"\"\"\n",
    "        # This function looks for columns that might reference other tables\n",
    "        potential_fks = []\n",
    "        \n",
    "        for file1, df1 in self.datasets.items():\n",
    "            for col1 in df1.columns:\n",
    "                col1_values = set(df1[col1].dropna().astype(str))\n",
    "                \n",
    "                for file2, df2 in self.datasets.items():\n",
    "                    if file1 != file2:\n",
    "                        for col2 in df2.columns:\n",
    "                            col2_values = set(df2[col2].dropna().astype(str))\n",
    "                            \n",
    "                            # Check if values in col1 exist in col2\n",
    "                            intersection = col1_values & col2_values\n",
    "                            if len(intersection) > 0:\n",
    "                                overlap_ratio = len(intersection) / len(col1_values) if len(col1_values) > 0 else 0\n",
    "                                \n",
    "                                if overlap_ratio > 0.1:  # At least 10% overlap\n",
    "                                    potential_fks.append({\n",
    "                                        'from_table': file1,\n",
    "                                        'from_column': col1,\n",
    "                                        'to_table': file2,\n",
    "                                        'to_column': col2,\n",
    "                                        'overlap_count': len(intersection),\n",
    "                                        'overlap_ratio': round(overlap_ratio, 3)\n",
    "                                    })\n",
    "        \n",
    "        # Sort by overlap ratio\n",
    "        potential_fks.sort(key=lambda x: x['overlap_ratio'], reverse=True)\n",
    "        \n",
    "        # Show top relationships\n",
    "        for fk in potential_fks[:15]:  # Show top 15\n",
    "            print(f\"  {fk['from_table']}.{fk['from_column']} â†’ {fk['to_table']}.{fk['to_column']}\")\n",
    "            print(f\"    Overlap: {fk['overlap_count']} values ({fk['overlap_ratio']} ratio)\")\n",
    "    \n",
    "    def generate_insights(self):\n",
    "        \"\"\"Generate insights about the dataset structure and purpose\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DATASET INSIGHTS AND PURPOSE\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        insights = {\n",
    "            'high_confidence.csv': \"Likely contains high-confidence drug-adverse event associations\",\n",
    "            'product_adverse_effect.csv': \"Maps drug products to adverse effects/reactions\",\n",
    "            'product_label.csv': \"Contains drug product labeling information\",\n",
    "            'product_to_rxnorm.csv': \"Maps products to RxNorm standardized drug codes\",\n",
    "            'vocab_meddra_adverse_effect.csv': \"MedDRA vocabulary for adverse effects standardization\",\n",
    "            'vocab_rxnorm_ingredient.csv': \"RxNorm vocabulary for drug ingredients\",\n",
    "            'vocab_rxnorm_ingredient_to_product.csv': \"Maps RxNorm ingredients to products\",\n",
    "            'vocab_rxnorm_product.csv': \"RxNorm vocabulary for drug products\"\n",
    "        }\n",
    "        \n",
    "        for file_name in self.datasets.keys():\n",
    "            print(f\"\\nðŸ“‹ {file_name}:\")\n",
    "            print(f\"   Purpose: {insights.get(file_name, 'Unknown purpose')}\")\n",
    "            \n",
    "            # Analyze data characteristics\n",
    "            df = self.datasets[file_name]\n",
    "            \n",
    "            # Look for patterns in column names\n",
    "            columns = df.columns.tolist()\n",
    "            print(f\"   Key characteristics:\")\n",
    "            \n",
    "            if any('rxnorm' in col.lower() for col in columns):\n",
    "                print(\"   - Contains RxNorm standardized drug codes\")\n",
    "            if any('meddra' in col.lower() for col in columns):\n",
    "                print(\"   - Contains MedDRA standardized adverse event codes\")\n",
    "            if any('product' in col.lower() for col in columns):\n",
    "                print(\"   - References drug products\")\n",
    "            if any('ingredient' in col.lower() for col in columns):\n",
    "                print(\"   - References drug ingredients\")\n",
    "            if any('adverse' in col.lower() or 'effect' in col.lower() for col in columns):\n",
    "                print(\"   - Contains adverse event information\")\n",
    "            if any('label' in col.lower() for col in columns):\n",
    "                print(\"   - Contains labeling/regulatory information\")\n",
    "            if any('confidence' in col.lower() for col in columns):\n",
    "                print(\"   - Includes confidence scores or high-confidence associations\")\n",
    "    \n",
    "    def suggest_connections(self):\n",
    "        \"\"\"Suggest how datasets can be connected\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUGGESTED DATASET CONNECTIONS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        connections = [\n",
    "            {\n",
    "                'description': \"Core Drug-Adverse Event Analysis\",\n",
    "                'tables': ['high_confidence.csv', 'product_adverse_effect.csv'],\n",
    "                'connection': \"Both contain drug-adverse event relationships\"\n",
    "            },\n",
    "            {\n",
    "                'description': \"Drug Product Standardization\",\n",
    "                'tables': ['product_to_rxnorm.csv', 'vocab_rxnorm_product.csv'],\n",
    "                'connection': \"Map products to standardized RxNorm codes\"\n",
    "            },\n",
    "            {\n",
    "                'description': \"Ingredient-Product Mapping\",\n",
    "                'tables': ['vocab_rxnorm_ingredient.csv', 'vocab_rxnorm_ingredient_to_product.csv', 'vocab_rxnorm_product.csv'],\n",
    "                'connection': \"Complete ingredient-to-product relationship chain\"\n",
    "            },\n",
    "            {\n",
    "                'description': \"Adverse Event Standardization\",\n",
    "                'tables': ['product_adverse_effect.csv', 'vocab_meddra_adverse_effect.csv'],\n",
    "                'connection': \"Standardize adverse events using MedDRA vocabulary\"\n",
    "            },\n",
    "            {\n",
    "                'description': \"Product Information Enrichment\",\n",
    "                'tables': ['product_label.csv', 'product_to_rxnorm.csv'],\n",
    "                'connection': \"Enrich product data with labeling and standardized codes\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for i, conn in enumerate(connections, 1):\n",
    "            print(f\"\\n{i}. {conn['description']}:\")\n",
    "            print(f\"   Tables: {' + '.join(conn['tables'])}\")\n",
    "            print(f\"   Connection: {conn['connection']}\")\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "        self.load_datasets()\n",
    "        self.analyze_dataset_structure()\n",
    "        self.identify_key_columns()\n",
    "        self.analyze_relationships()\n",
    "        self.generate_insights()\n",
    "        self.suggest_connections()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ANALYSIS COMPLETE\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"The datasets appear to form a comprehensive drug safety and standardization system.\")\n",
    "        print(\"Key components:\")\n",
    "        print(\"- Drug product identification and standardization (RxNorm)\")\n",
    "        print(\"- Adverse event standardization (MedDRA)\")\n",
    "        print(\"- Drug-adverse event associations\")\n",
    "        print(\"- Product labeling information\")\n",
    "        print(\"- Ingredient-product relationships\")\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    explorer = DrugDatasetExplorer()\n",
    "    explorer.run_complete_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
