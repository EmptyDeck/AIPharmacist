{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f42dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available input devices:\n",
      "Input Device id 0: Microsoft Sound Mapper - Input\n",
      "Input Device id 1: 마이크(Microsoft® LifeCam VX-2000)\n",
      "Input Device id 2: 마이크(Realtek USB2.0 Audio)\n",
      "Input Device id 3: 마이크(Steam Streaming Microphone)\n",
      "Input Device id 11: 주 사운드 캡처 드라이버\n",
      "Input Device id 12: 마이크(Microsoft® LifeCam VX-2000)\n",
      "Input Device id 13: 마이크(Realtek USB2.0 Audio)\n",
      "Input Device id 14: 마이크(Steam Streaming Microphone)\n",
      "Input Device id 28: 마이크(Microsoft® LifeCam VX-2000)\n",
      "Input Device id 29: 마이크(Realtek USB2.0 Audio)\n",
      "Input Device id 30: 마이크(Steam Streaming Microphone)\n",
      "Input Device id 32: 머리에 거는 수화기 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(WH-1000XM3))\n",
      "Input Device id 34: Input (@System32\\drivers\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\n",
      ";(삼성 갤럭시 S2))\n",
      "Input Device id 36: 아날로그 커넥터 (Realtek USB2.0 Audio)\n",
      "Input Device id 37: 라인 (Realtek USB2.0 Audio)\n",
      "Input Device id 38: 마이크 (Realtek USB2.0 Audio)\n",
      "Input Device id 42: 라인 ()\n",
      "Input Device id 43: 마이크 (Microsoft® LifeCam VX-2000)\n",
      "Input Device id 44: 마이크 (Steam Streaming Microphone Wave)\n",
      "Input Device id 46: Input (Steam Streaming Speakers Wave)\n",
      "Input Device id 50: 헤드셋 마이크 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(DESKTOP-SPLBQKN))\n",
      "\n",
      "Default input device: [1] 마이크(Microsoft® LifeCam VX-2000)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'index': 1,\n",
       " 'structVersion': 2,\n",
       " 'name': '마이크(Microsoft® LifeCam VX-2000)',\n",
       " 'hostApi': 0,\n",
       " 'maxInputChannels': 1,\n",
       " 'maxOutputChannels': 0,\n",
       " 'defaultLowInputLatency': 0.09,\n",
       " 'defaultLowOutputLatency': 0.09,\n",
       " 'defaultHighInputLatency': 0.18,\n",
       " 'defaultHighOutputLatency': 0.18,\n",
       " 'defaultSampleRate': 44100.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "def list_input_devices():\n",
    "    p = pyaudio.PyAudio()\n",
    "    print(\"Available input devices:\")\n",
    "    for i in range(p.get_device_count()):\n",
    "        dev = p.get_device_info_by_index(i)\n",
    "        if dev['maxInputChannels'] > 0:\n",
    "            print(f\"Input Device id {i}: {dev['name']}\")\n",
    "    p.terminate()\n",
    "\n",
    "def get_default_input_device():\n",
    "    p = pyaudio.PyAudio()\n",
    "    default_dev = p.get_default_input_device_info()\n",
    "    print(f\"\\nDefault input device: [{default_dev['index']}] {default_dev['name']}\\n\")\n",
    "    p.terminate()\n",
    "    return default_dev\n",
    "\n",
    "# Place this at the start of your main() or before recording\n",
    "list_input_devices()\n",
    "get_default_input_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994eee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "녹음중... 말을 해주세요.\n",
      "사용자: Hey can you hear me \n",
      "AI: Yes, I can hear you. How can I assist you today?\n",
      "파일 삭제 오류: [WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'output.wav'\n",
      "5초 후 다음 입력을 대기합니다...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 180\u001b[39m\n\u001b[32m    177\u001b[39m         time.sleep(\u001b[32m5\u001b[39m)\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 177\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m파일 삭제 오류:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    176\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m5초 후 다음 입력을 대기합니다...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import time\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "# 환경변수 불러오기\n",
    "load_dotenv()\n",
    "\n",
    "# Watson API Credential\n",
    "STT_API_KEY = os.getenv('STT_API_KEY')\n",
    "STT_URL = os.getenv('STT_URL')\n",
    "TTS_API_KEY = os.getenv('TTS_API_KEY')\n",
    "TTS_URL = os.getenv('TTS_URL')\n",
    "\n",
    "# LLM Credential\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "PROJECT_ID = os.getenv('PROJECT_ID')\n",
    "IBM_CLOUD_URL = os.getenv('IBM_CLOUD_URL')\n",
    "MODEL_ID = os.getenv('MODEL_ID')\n",
    "\n",
    "# 오디오 설정\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "SILENCE_THRESHOLD = 1000\n",
    "SILENCE_DURATION = 2\n",
    "\n",
    "# LLM 세팅\n",
    "generate_params = {GenParams.MAX_NEW_TOKENS: 900}\n",
    "model = Model(\n",
    "    model_id=MODEL_ID,\n",
    "    params=generate_params,\n",
    "    credentials={\"apikey\": API_KEY, \"url\": IBM_CLOUD_URL},\n",
    "    project_id=PROJECT_ID\n",
    ")\n",
    "\n",
    "def record_audio():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    print(\"녹음중... 말을 해주세요.\")\n",
    "\n",
    "    frames = []\n",
    "    silent_chunks = 0\n",
    "\n",
    "    while True:\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "        amplitude = np.abs(audio_data).mean()\n",
    "        if amplitude < SILENCE_THRESHOLD:\n",
    "            silent_chunks += 1\n",
    "        else:\n",
    "            silent_chunks = 0\n",
    "        if silent_chunks > (SILENCE_DURATION * RATE / CHUNK):\n",
    "            break\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(\"input.wav\", 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    return \"input.wav\"\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "    endpoint = f\"{STT_URL}/v1/recognize\"\n",
    "    headers = {\"Content-Type\": \"audio/wav\"}\n",
    "    auth = (\"apikey\", STT_API_KEY)\n",
    "\n",
    "    with open(audio_file, 'rb') as f:\n",
    "        response = requests.post(\n",
    "            endpoint,\n",
    "            headers=headers,\n",
    "            data=f,\n",
    "            auth=auth\n",
    "        )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if result.get(\"results\"):\n",
    "            return result[\"results\"][0][\"alternatives\"][0][\"transcript\"]\n",
    "        else:\n",
    "            return \"(음성 인식 결과 없음)\"\n",
    "    else:\n",
    "        print(\"STT 오류:\", response.status_code)\n",
    "        print(response.text)\n",
    "        return \"(STT 오류)\"\n",
    "\n",
    "def generate_response(text):\n",
    "    system_prompt = \"You are a helpful assistant.\"\n",
    "    formatted_prompt = f\"<<SYS>>\\n{system_prompt.strip()}\\n<</SYS>>\\n\\n[INST]{text.strip()}[/INST]\"\n",
    "    try:\n",
    "        response = model.generate(prompt=formatted_prompt)[\"results\"][0][\"generated_text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(\"LLM 오류:\", str(e))\n",
    "        response = \"(LLM 오류)\"\n",
    "    return response\n",
    "\n",
    "def text_to_speech(text):\n",
    "    endpoint = f\"{TTS_URL}/v1/synthesize\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Accept\": \"audio/wav\"}\n",
    "    payload = {\n",
    "        \"text\": text\n",
    "    }\n",
    "    params = {\"voice\": \"en-GB_ChloeNatural\"}\n",
    "    auth = (\"apikey\", TTS_API_KEY)\n",
    "\n",
    "    response = requests.post(\n",
    "        endpoint,\n",
    "        headers=headers,\n",
    "        params=params,\n",
    "        json=payload,\n",
    "        auth=auth,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(\"output.wav\", \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        return \"output.wav\"\n",
    "    else:\n",
    "        print(\"TTS 오류:\", response.status_code)\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "def play_audio(audio_file):\n",
    "    wf = wave.open(audio_file, 'rb')\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "    data = wf.readframes(CHUNK)\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(CHUNK)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        audio_file = record_audio()    # 1. 녹음\n",
    "        transcribed = speech_to_text(audio_file)   # 2. 음성→텍스트\n",
    "        print(\"사용자:\", transcribed)\n",
    "\n",
    "        response_text = generate_response(transcribed)   # 3. LLM이 답변 만듦\n",
    "        print(\"AI:\", response_text)\n",
    "\n",
    "        response_audio = text_to_speech(response_text)   # 4. 답변을 음성으로 변환\n",
    "        if response_audio:\n",
    "            play_audio(response_audio)  # 5. 음성 답변 재생\n",
    "\n",
    "        # 파일 정리\n",
    "        try:\n",
    "            os.remove(audio_file)\n",
    "            if response_audio:\n",
    "                os.remove(response_audio)\n",
    "        except Exception as e:\n",
    "            print(\"파일 삭제 오류:\", str(e))\n",
    "\n",
    "        print(\"5초 후 다음 입력을 대기합니다...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
