import logging
from typing import Optional

from fastapi import APIRouter
from pydantic import BaseModel
from ibm_watson_machine_learning.foundation_models import Model
from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams
from core.config import settings

router = APIRouter()

# ëª¨ë¸ ì¸ì¦ ì •ë³´ ë° ì´ˆê¸°í™”
creds = {
    "url": settings.IBM_CLOUD_URL,
    "apikey": settings.API_KEY
}

try:
    model = Model(
        model_id='ibm/granite-3-3-8b-instruct',
        credentials=creds,
        project_id=settings.PROJECT_ID
    )
except Exception as e:
    logging.error(f"ğŸ›‘ IBM ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    raise e

def get_completion(prompt: str, max_tokens: int = 200, temperature: float = 0.7) -> str:
    try:
        response = model.generate(
            prompt=prompt,
            params={
                GenParams.MAX_NEW_TOKENS: 100,
                GenParams.TEMPERATURE: temperature
            }
        )
        return response['results'][0]['generated_text']
    except Exception as e:
        logging.error(f"ğŸ›‘ GPT ì‘ë‹µ ì˜¤ë¥˜: {e}")
        return "âš ï¸ GPT ì‘ë‹µì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

class GPTRequest(BaseModel):
    message: str

@router.post("/audio/gpt")
async def gpt_response(request: GPTRequest):
    prompt = f"""
    ë‹¹ì‹ ì€ 'ë‹¥í„°ì™“ìŠ¨'ì´ë¼ëŠ” ì‚¬ëŒì˜ ì•½êµ­ ì˜ì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ë©”ì„¸ì§€ì— ëŒ€í•´ì„œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ê·¸ë¦¬ê³  ë‹µë³€ì€ 3ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ì‚¬ìš©ìì˜ ì…ë ¥ì€ ì´ìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì‚¬ìš©ìëŠ” STTë¥¼ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— ë§Œì•½ ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì´ìƒí•˜ë‹¤ë©´ ëˆˆì¹˜ë¡œ ì´í•´í•´ì£¼ì„¸ìš”.
    ``````
    """
    response_text = get_completion(prompt)
    return {"text": response_text}



# ì—ì´ì „íŠ¸ ì½”ë“œ(ì„±ëŠ¥ í–¥ìƒ í•´ì•¼í•¨)
# import requests
# import logging
# from fastapi import APIRouter
# from pydantic import BaseModel
# from core.config import settings

# router = APIRouter()

# class GPTRequest(BaseModel):
#     message: str

# @router.post("/audio/gpt")
# async def gpt_response(request: GPTRequest):
#     print("GPT ìš”ì²­ ìˆ˜ì‹ :", request.message)
    
#     response_text = get_completion(request.message)
#     return {"text": response_text}

# def get_completion(user_message: str) -> str:
#     try:
#         # í† í° íšë“
#         token_response = requests.post('https://iam.cloud.ibm.com/identity/token', 
#                                     data={"apikey": settings.API_KEY, "grant_type": 'urn:ibm:params:oauth:grant-type:apikey'})
#         mltoken = token_response.json()["access_token"]
        
#         # í—¤ë” ì„¤ì •
#         header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}
        
#         # í˜ì´ë¡œë“œ - ì½”ë“œ 2ì™€ ë™ì¼í•œ êµ¬ì¡°
#         payload_scoring = {
#             "messages": [
#                 {"role": "user", "content": user_message}
#             ]
#         }
        
#         # API í˜¸ì¶œ
#         response_scoring = requests.post('https://us-south.ml.cloud.ibm.com/ml/v4/deployments/a13f7396-1142-40d6-9531-f7719be5f3fe/ai_service?version=2021-05-01', 
#                                        json=payload_scoring, headers=header)
        
#         # ì‘ë‹µ í™•ì¸ (ì½”ë“œ 2ì²˜ëŸ¼)
#         #print("Scoring response")
#         try:
#             response_data = response_scoring.json()
#             print(response_data)
#             # choicesê°€ ìˆìœ¼ë©´ íŒŒì‹±, ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µ ë°˜í™˜
#             if 'choices' in response_data:
#                 return response_data['choices'][0]['message']['content']
#             else:
#                 # ë‹¤ë¥¸ í˜•ì‹ì˜ ì‘ë‹µì¼ ê²½ìš° ì „ì²´ ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë°˜í™˜
#                 return str(response_data)
#         except ValueError:
#             print(response_scoring.text)
#             return response_scoring.text
        
#     except Exception as e:
#         logging.error(f"ğŸ›‘ GPT ì‘ë‹µ ì˜¤ë¥˜: {e}")
#         return "âš ï¸ GPT ì‘ë‹µì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."