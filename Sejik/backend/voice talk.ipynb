{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994eee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'ibm/granite-13b-chat-v2' is not supported for this environment. Supported models: ['cross-encoder/ms-marco-minilm-l-12-v2', 'google/flan-t5-xl', 'ibm/granite-13b-instruct-v2', 'ibm/granite-3-1-8b-base', 'ibm/granite-3-2-8b-instruct', 'ibm/granite-3-2b-instruct', 'ibm/granite-3-3-8b-instruct', 'ibm/granite-3-8b-instruct', 'ibm/granite-8b-code-instruct', 'ibm/granite-embedding-107m-multilingual', 'ibm/granite-embedding-278m-multilingual', 'ibm/granite-guardian-3-2b', 'ibm/granite-guardian-3-8b', 'ibm/granite-ttm-1024-96-r2', 'ibm/granite-ttm-1536-96-r2', 'ibm/granite-ttm-512-96-r2', 'ibm/granite-vision-3-2-2b', 'ibm/slate-125m-english-rtrvr', 'ibm/slate-125m-english-rtrvr-v2', 'ibm/slate-30m-english-rtrvr', 'ibm/slate-30m-english-rtrvr-v2', 'intfloat/multilingual-e5-large', 'meta-llama/llama-2-13b-chat', 'meta-llama/llama-3-1-8b', 'meta-llama/llama-3-2-11b-vision-instruct', 'meta-llama/llama-3-2-1b-instruct', 'meta-llama/llama-3-2-3b-instruct', 'meta-llama/llama-3-2-90b-vision-instruct', 'meta-llama/llama-3-3-70b-instruct', 'meta-llama/llama-3-405b-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct-fp8', 'meta-llama/llama-guard-3-11b-vision', 'mistralai/mistral-large', 'mistralai/mistral-medium-2505', 'mistralai/mistral-small-3-1-24b-instruct-2503', 'mistralai/pixtral-12b', 'sentence-transformers/all-minilm-l12-v2', 'sentence-transformers/all-minilm-l6-v2']\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Model 'ibm/granite-13b-chat-v2' is not supported for this environment. Supported models: ['cross-encoder/ms-marco-minilm-l-12-v2', 'google/flan-t5-xl', 'ibm/granite-13b-instruct-v2', 'ibm/granite-3-1-8b-base', 'ibm/granite-3-2-8b-instruct', 'ibm/granite-3-2b-instruct', 'ibm/granite-3-3-8b-instruct', 'ibm/granite-3-8b-instruct', 'ibm/granite-8b-code-instruct', 'ibm/granite-embedding-107m-multilingual', 'ibm/granite-embedding-278m-multilingual', 'ibm/granite-guardian-3-2b', 'ibm/granite-guardian-3-8b', 'ibm/granite-ttm-1024-96-r2', 'ibm/granite-ttm-1536-96-r2', 'ibm/granite-ttm-512-96-r2', 'ibm/granite-vision-3-2-2b', 'ibm/slate-125m-english-rtrvr', 'ibm/slate-125m-english-rtrvr-v2', 'ibm/slate-30m-english-rtrvr', 'ibm/slate-30m-english-rtrvr-v2', 'intfloat/multilingual-e5-large', 'meta-llama/llama-2-13b-chat', 'meta-llama/llama-3-1-8b', 'meta-llama/llama-3-2-11b-vision-instruct', 'meta-llama/llama-3-2-1b-instruct', 'meta-llama/llama-3-2-3b-instruct', 'meta-llama/llama-3-2-90b-vision-instruct', 'meta-llama/llama-3-3-70b-instruct', 'meta-llama/llama-3-405b-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct-fp8', 'meta-llama/llama-guard-3-11b-vision', 'mistralai/mistral-large', 'mistralai/mistral-medium-2505', 'mistralai/mistral-small-3-1-24b-instruct-2503', 'mistralai/pixtral-12b', 'sentence-transformers/all-minilm-l12-v2', 'sentence-transformers/all-minilm-l6-v2']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWMLClientError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Initialize LLM\u001b[39;00m\n\u001b[32m     60\u001b[39m generate_params = {GenParams.MAX_NEW_TOKENS: \u001b[32m900\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m model = \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerate_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapikey\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mIBM_CLOUD_URL\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPROJECT_ID\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrecord_audio\u001b[39m():\n\u001b[32m     69\u001b[39m     p = pyaudio.PyAudio()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ibm/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/model.py:82\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model_id, credentials, params, project_id, space_id, verify)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m     76\u001b[39m              model_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     77\u001b[39m              credentials: \u001b[38;5;28mdict\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m              space_id: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     81\u001b[39m              verify=\u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[43mModelInference\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mspace_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspace_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ibm/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/inference/model_inference.py:148\u001b[39m, in \u001b[36mModelInference.__init__\u001b[39m\u001b[34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(error_msg=\u001b[33m\"\u001b[39m\u001b[33mOperation is unsupported for this release.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_id:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28mself\u001b[39m._inference = \u001b[43mFMModelInference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m._inference = DeploymentModelInference(deployment_id=\u001b[38;5;28mself\u001b[39m.deployment_id,\n\u001b[32m    153\u001b[39m                                                params=\u001b[38;5;28mself\u001b[39m.params,\n\u001b[32m    154\u001b[39m                                                api_client=\u001b[38;5;28mself\u001b[39m._client)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ibm/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/inference/fm_model_inference.py:44\u001b[39m, in \u001b[36mFMModelInference.__init__\u001b[39m\u001b[34m(self, model_id, params, api_client)\u001b[39m\n\u001b[32m     42\u001b[39m supported_models = [model_spec[\u001b[33m'\u001b[39m\u001b[33mmodel_id\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m model_spec \u001b[38;5;129;01min\u001b[39;00m get_model_specs(\u001b[38;5;28mself\u001b[39m._client.wml_credentials.get(\u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m)).get(\u001b[33m'\u001b[39m\u001b[33mresources\u001b[39m\u001b[33m'\u001b[39m, [])]\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_models:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(error_msg=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not supported for this environment. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m                                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupported models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_models\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# check if model is in constricted mode\u001b[39;00m\n\u001b[32m     48\u001b[39m _check_model_state(\u001b[38;5;28mself\u001b[39m._client.wml_credentials.get(\u001b[33m'\u001b[39m\u001b[33murl\u001b[39m\u001b[33m'\u001b[39m), \u001b[38;5;28mself\u001b[39m.model_id)\n",
      "\u001b[31mWMLClientError\u001b[39m: Model 'ibm/granite-13b-chat-v2' is not supported for this environment. Supported models: ['cross-encoder/ms-marco-minilm-l-12-v2', 'google/flan-t5-xl', 'ibm/granite-13b-instruct-v2', 'ibm/granite-3-1-8b-base', 'ibm/granite-3-2-8b-instruct', 'ibm/granite-3-2b-instruct', 'ibm/granite-3-3-8b-instruct', 'ibm/granite-3-8b-instruct', 'ibm/granite-8b-code-instruct', 'ibm/granite-embedding-107m-multilingual', 'ibm/granite-embedding-278m-multilingual', 'ibm/granite-guardian-3-2b', 'ibm/granite-guardian-3-8b', 'ibm/granite-ttm-1024-96-r2', 'ibm/granite-ttm-1536-96-r2', 'ibm/granite-ttm-512-96-r2', 'ibm/granite-vision-3-2-2b', 'ibm/slate-125m-english-rtrvr', 'ibm/slate-125m-english-rtrvr-v2', 'ibm/slate-30m-english-rtrvr', 'ibm/slate-30m-english-rtrvr-v2', 'intfloat/multilingual-e5-large', 'meta-llama/llama-2-13b-chat', 'meta-llama/llama-3-1-8b', 'meta-llama/llama-3-2-11b-vision-instruct', 'meta-llama/llama-3-2-1b-instruct', 'meta-llama/llama-3-2-3b-instruct', 'meta-llama/llama-3-2-90b-vision-instruct', 'meta-llama/llama-3-3-70b-instruct', 'meta-llama/llama-3-405b-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct-fp8', 'meta-llama/llama-guard-3-11b-vision', 'mistralai/mistral-large', 'mistralai/mistral-medium-2505', 'mistralai/mistral-small-3-1-24b-instruct-2503', 'mistralai/pixtral-12b', 'sentence-transformers/all-minilm-l12-v2', 'sentence-transformers/all-minilm-l6-v2']"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# STT and TTS credentials\n",
    "STT_API_KEY = os.getenv('STT_API_KEY')\n",
    "STT_URL = os.getenv('STT_URL')\n",
    "TTS_API_KEY = os.getenv('TTS_API_KEY')\n",
    "TTS_URL = os.getenv('TTS_URL')\n",
    "\n",
    "# LLM credentials\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "PROJECT_ID = os.getenv('PROJECT_ID')\n",
    "IBM_CLOUD_URL = os.getenv('IBM_CLOUD_URL')\n",
    "MODEL_ID = os.getenv('MODEL_ID')\n",
    "\n",
    "# Optional: Add error checking\n",
    "MISSING_ENV = []\n",
    "\n",
    "if not STT_API_KEY:\n",
    "    MISSING_ENV.append(\"STT_API_KEY\")\n",
    "if not STT_URL:\n",
    "    MISSING_ENV.append(\"STT_URL\")\n",
    "if not TTS_API_KEY:\n",
    "    MISSING_ENV.append(\"TTS_API_KEY\")\n",
    "if not TTS_URL:\n",
    "    MISSING_ENV.append(\"TTS_URL\")\n",
    "if not API_KEY:\n",
    "    MISSING_ENV.append(\"API_KEY\")\n",
    "if not PROJECT_ID:\n",
    "    MISSING_ENV.append(\"PROJECT_ID\")\n",
    "if not IBM_CLOUD_URL:\n",
    "    MISSING_ENV.append(\"IBM_CLOUD_URL\")\n",
    "if not MODEL_ID:\n",
    "    MISSING_ENV.append(\"MODEL_ID\")\n",
    "\n",
    "if MISSING_ENV:\n",
    "    raise ValueError(f\"Missing required environment variables: {', '.join(MISSING_ENV)}. Please check your .env file.\")\n",
    "\n",
    "\n",
    "# Audio recording settings\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "SILENCE_THRESHOLD = 500  # Amplitude threshold for silence detection\n",
    "SILENCE_DURATION = 2  # Seconds of silence to stop recording\n",
    "\n",
    "# Initialize LLM\n",
    "generate_params = {GenParams.MAX_NEW_TOKENS: 900}\n",
    "model = Model(\n",
    "    model_id=MODEL_ID,\n",
    "    params=generate_params,\n",
    "    credentials={\"apikey\": API_KEY, \"url\": IBM_CLOUD_URL},\n",
    "    project_id=PROJECT_ID\n",
    ")\n",
    "\n",
    "def record_audio():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    print(\"Recording... Speak now.\")\n",
    "    \n",
    "    frames = []\n",
    "    silent_chunks = 0\n",
    "    recording = True\n",
    "    \n",
    "    while recording:\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "        \n",
    "        # Convert audio chunk to numpy array for amplitude analysis\n",
    "        audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "        amplitude = np.abs(audio_data).mean()\n",
    "        \n",
    "        # Check for silence\n",
    "        if amplitude < SILENCE_THRESHOLD:\n",
    "            silent_chunks += 1\n",
    "        else:\n",
    "            silent_chunks = 0\n",
    "        \n",
    "        # Stop recording after sustained silence\n",
    "        if silent_chunks > (SILENCE_DURATION * RATE / CHUNK):\n",
    "            recording = False\n",
    "    \n",
    "    print(\"Stopped recording.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    # Save audio to WAV file\n",
    "    wf = wave.open(\"input.wav\", 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    return \"input.wav\"\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "    headers = {\"Content-Type\": \"audio/wav\"}\n",
    "    with open(audio_file, 'rb') as f:\n",
    "        response = requests.post(\n",
    "            STT_URL,\n",
    "            headers=headers,\n",
    "            data=f,\n",
    "            auth=(\"apikey\", STT_API_KEY)\n",
    "        )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if result.get(\"results\"):\n",
    "            return result[\"results\"][0][\"alternatives\"][0][\"transcript\"]\n",
    "    return \"Error transcribing audio.\"\n",
    "\n",
    "def generate_response(text):\n",
    "    system_prompt = \"You are a helpful assistant.\"\n",
    "    formatted_prompt = f\"<<SYS>>\\n{system_prompt.strip()}\\n<</SYS>>\\n\\n[INST]{text.strip()}[/INST]\"\n",
    "    response = model.generate(prompt=formatted_prompt)[\"results\"][0][\"generated_text\"].strip()\n",
    "    return response\n",
    "\n",
    "def text_to_speech(text):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"audio/wav\"\n",
    "    }\n",
    "    data = json.dumps({\"text\": text})\n",
    "    response = requests.post(\n",
    "        TTS_URL + \"?voice=en-US_MichaelV3Voice\",\n",
    "        headers=headers,\n",
    "        data=data,\n",
    "        auth=(\"apikey\", TTS_API_KEY)\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(\"output.wav\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return \"output.wav\"\n",
    "    return None\n",
    "\n",
    "def play_audio(audio_file):\n",
    "    wf = wave.open(audio_file, 'rb')\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "        format=p.get_format_from_width(wf.getsampwidth()),\n",
    "        channels=wf.getnchannels(),\n",
    "        rate=wf.getframerate(),\n",
    "        output=True\n",
    "    )\n",
    "    \n",
    "    data = wf.readframes(CHUNK)\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(CHUNK)\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        # Step 1: Record audio\n",
    "        audio_file = record_audio()\n",
    "        \n",
    "        # Step 2: Transcribe audio to text\n",
    "        transcribed_text = speech_to_text(audio_file)\n",
    "        print(f\"User said: {transcribed_text}\")\n",
    "        \n",
    "        if \"Error\" in transcribed_text:\n",
    "            print(\"Failed to transcribe speech. Try again.\")\n",
    "            continue\n",
    "        \n",
    "        # Step 3: Generate response with LLM\n",
    "        response_text = generate_response(transcribed_text)\n",
    "        print(f\"AI response: {response_text}\")\n",
    "        \n",
    "        # Step 4: Convert response to speech\n",
    "        response_audio = text_to_speech(response_text)\n",
    "        if response_audio:\n",
    "            # Step 5: Play the response\n",
    "            play_audio(response_audio)\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(audio_file)\n",
    "        if response_audio:\n",
    "            os.remove(response_audio)\n",
    "        print(\"Puase for 5 seconds\")\n",
    "        time.sleep(5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
