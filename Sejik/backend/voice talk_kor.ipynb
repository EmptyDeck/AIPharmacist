{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e010e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ï¸ ë§í•´ì£¼ì„¸ìš”... (ì ì‹œ ë©ˆì¶”ë©´ ë…¹ìŒì´ ì¢…ë£Œë©ë‹ˆë‹¤)\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "STT_API_KEY = os.getenv('STT_API_KEY')\n",
    "STT_URL = os.getenv('STT_URL')\n",
    "TTS_API_KEY = os.getenv('TTS_API_KEY')\n",
    "TTS_URL = os.getenv('TTS_URL')\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "PROJECT_ID = os.getenv('PROJECT_ID')\n",
    "IBM_CLOUD_URL = os.getenv('IBM_CLOUD_URL')\n",
    "MODEL_ID = os.getenv('MODEL_ID')\n",
    "\n",
    "# ëˆ„ë½ëœ í•­ëª© í™•ì¸\n",
    "missing = []\n",
    "for var in ['STT_API_KEY', 'STT_URL', 'TTS_API_KEY', 'TTS_URL', 'API_KEY', 'PROJECT_ID', 'IBM_CLOUD_URL', 'MODEL_ID']:\n",
    "    if eval(var) is None:\n",
    "        missing.append(var)\n",
    "if missing:\n",
    "    raise ValueError(f\"ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}\")\n",
    "\n",
    "# ì˜¤ë””ì˜¤ ì„¤ì •\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "SILENCE_THRESHOLD = 500\n",
    "SILENCE_DURATION = 2\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "generate_params = {GenParams.MAX_NEW_TOKENS: 900}\n",
    "model = Model(\n",
    "    model_id=MODEL_ID,\n",
    "    params=generate_params,\n",
    "    credentials={\"apikey\": API_KEY, \"url\": IBM_CLOUD_URL},\n",
    "    project_id=PROJECT_ID\n",
    ")\n",
    "\n",
    "def record_audio():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    print(\"ğŸ™ï¸ ë§í•´ì£¼ì„¸ìš”... (ì ì‹œ ë©ˆì¶”ë©´ ë…¹ìŒì´ ì¢…ë£Œë©ë‹ˆë‹¤)\")\n",
    "\n",
    "    frames = []\n",
    "    silent_chunks = 0\n",
    "\n",
    "    while True:\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "        audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "        amplitude = np.abs(audio_data).mean()\n",
    "\n",
    "        if amplitude < SILENCE_THRESHOLD:\n",
    "            silent_chunks += 1\n",
    "        else:\n",
    "            silent_chunks = 0\n",
    "\n",
    "        if silent_chunks > (SILENCE_DURATION * RATE / CHUNK):\n",
    "            break\n",
    "\n",
    "    print(\"ğŸ›‘ ë…¹ìŒ ì¢…ë£Œ\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(\"input.wav\", 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    return \"input.wav\"\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "    headers = {\"Content-Type\": \"audio/wav\"}\n",
    "    with open(audio_file, 'rb') as f:\n",
    "        response = requests.post(\n",
    "            STT_URL,\n",
    "            headers=headers,\n",
    "            data=f,\n",
    "            params={\"model\": \"ko-KR_Multimedia\"},\n",
    "            auth=(\"apikey\", STT_API_KEY)\n",
    "        )\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if result.get(\"results\"):\n",
    "            return result[\"results\"][0][\"alternatives\"][0][\"transcript\"]\n",
    "    return \"ìŒì„± ì¸ì‹ ì˜¤ë¥˜\"\n",
    "\n",
    "def generate_response(text):\n",
    "    system_prompt = \"ë‹¹ì‹ ì€ ìœ ìš©í•œ í•œêµ­ì–´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.\"\n",
    "    formatted_prompt = f\"<<SYS>>\\n{system_prompt.strip()}\\n<</SYS>>\\n\\n[INST]{text.strip()}[/INST]\"\n",
    "    response = model.generate(prompt=formatted_prompt)\n",
    "    return response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "def text_to_speech(text):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"audio/wav\"\n",
    "    }\n",
    "    data = json.dumps({\"text\": text})\n",
    "    response = requests.post(\n",
    "        TTS_URL + \"?voice=ko-KR_JinV3Voice\",\n",
    "        headers=headers,\n",
    "        data=data,\n",
    "        auth=(\"apikey\", TTS_API_KEY)\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        with open(\"output.wav\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return \"output.wav\"\n",
    "    return None\n",
    "\n",
    "def play_audio(audio_file):\n",
    "    wf = wave.open(audio_file, 'rb')\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "        format=p.get_format_from_width(wf.getsampwidth()),\n",
    "        channels=wf.getnchannels(),\n",
    "        rate=wf.getframerate(),\n",
    "        output=True\n",
    "    )\n",
    "    data = wf.readframes(CHUNK)\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(CHUNK)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        audio_file = record_audio()\n",
    "        text = speech_to_text(audio_file)\n",
    "        print(f\"ğŸ—£ï¸ ì‚¬ìš©ì: {text}\")\n",
    "\n",
    "        if \"ì˜¤ë¥˜\" in text:\n",
    "            print(\"âš ï¸ ìŒì„± ì¸ì‹ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
    "            continue\n",
    "\n",
    "        response = generate_response(text)\n",
    "        print(f\"ğŸ¤– AI ì‘ë‹µ: {response}\")\n",
    "\n",
    "        audio_response = text_to_speech(response)\n",
    "        if audio_response:\n",
    "            play_audio(audio_response)\n",
    "\n",
    "        os.remove(audio_file)\n",
    "        if audio_response:\n",
    "            os.remove(audio_response)\n",
    "\n",
    "        print(\"â¸ 5ì´ˆê°„ ëŒ€ê¸° ì¤‘...\\n\")\n",
    "        time.sleep(5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
