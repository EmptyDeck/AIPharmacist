# Sejik/Demo/backend/api/chat.py
import httpx
import requests
import json
from fastapi import APIRouter, HTTPException
from schemas.chat import ChatRequest, ChatResponse
from core.config import settings
import asyncio
from typing import Optional
from .chatbot.explainAI import ExplainAI
from .chatbot.warnAI import WarnAI
from .chatbot.calendarAI import CalendarAI

from pathlib import Path
from utils.watsonx_vision import process_image_with_watsonx_vision


# APIRouter ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
router = APIRouter()

# ì „ë¬¸ AI ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë“¤
_explain_ai: Optional[ExplainAI] = None
_warn_ai: Optional[WarnAI] = None
_calendar_ai: Optional[CalendarAI] = None

# ì‚¬ìš©ì ì„¸ì…˜ ì €ì¥ (ì‹¤ì œë¡œëŠ” Redisë‚˜ DB ì‚¬ìš©)
_user_sessions = {}

# IBM Watson í† í° ìºì‹œ
_watson_token_cache = {"token": None, "expires_at": 0}




def get_watson_token() -> str:
    """IBM Watson API í† í°ì„ ë°œê¸‰ë°›ìŠµë‹ˆë‹¤"""
    import time
    
    current_time = time.time()
    if (_watson_token_cache["token"] and 
        current_time < _watson_token_cache["expires_at"] - 300):
        return _watson_token_cache["token"]
    
    if not settings.WATSONX_API_KEY:
        raise HTTPException(status_code=500, detail="IBM Watson API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        token_response = requests.post(
            'https://iam.cloud.ibm.com/identity/token',
            data={
                "apikey": settings.WATSONX_API_KEY,
                "grant_type": 'urn:ibm:params:oauth:grant-type:apikey'
            }
        )
        
        if token_response.status_code != 200:
            raise Exception(f"í† í° ë°œê¸‰ ì‹¤íŒ¨: {token_response.status_code}")
            
        token_data = token_response.json()
        mltoken = token_data.get("access_token")
        expires_in = token_data.get("expires_in", 3600)
        
        if not mltoken:
            raise Exception("í† í° ë°œê¸‰ ì‹¤íŒ¨!")
        
        _watson_token_cache["token"] = mltoken
        _watson_token_cache["expires_at"] = current_time + expires_in
        
        return mltoken
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"IBM Watson í† í° ë°œê¸‰ ì‹¤íŒ¨: {str(e)}")



def get_specialized_agents():
    """ì „ë¬¸ AI ì—ì´ì „íŠ¸ë“¤ì„ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤"""
    global _explain_ai, _warn_ai, _calendar_ai
    
    if _explain_ai is None:
        _explain_ai = ExplainAI()
    if _warn_ai is None:
        _warn_ai = WarnAI()
    if _calendar_ai is None:
        _calendar_ai = CalendarAI()
    
    return _explain_ai, _warn_ai, _calendar_ai

def call_llm(user_input: str) -> str:
    """LLM í˜¸ì¶œí•´ì„œ ê²°ê³¼ ë°›ê¸°"""
    try:
        mltoken = get_watson_token()
        
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {mltoken}',
            'Accept': 'application/json'
        }
        
        ibm_ai_service_url = getattr(settings, 'WATSONX_DEPLOYMENT_URL', 
                                   'https://us-south.ml.cloud.ibm.com/ml/v1/deployments/b53e3a10-1ac5-4018-a0c2-29dda45e57f2/text/generation?version=2021-05-01')
        
        payload_scoring = {
            "parameters": {
                "prompt_variables": {
                    "default": user_input
                }
            }
        }
        
        response = requests.post(
            ibm_ai_service_url,
            headers=headers,
            json=payload_scoring,
            stream=False
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'results' in result and len(result['results']) > 0:
                generated_text = result['results'][0]['generated_text']
                first_line = generated_text.split('\n\nInput')[0].strip()
                return first_line
            else:
                return "ì‘ë‹µì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            raise Exception(f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
    

# chat.py ìƒë‹¨ì— ì¶”ê°€
from utils.cache import get_vision_result, set_vision_result

@router.post("/chat", response_model=ChatResponse, summary="ì˜ë£Œ AI ì±„íŒ…")
async def get_chat_response(request: ChatRequest):
    try:
        request.question = (f"{request.question} " f"ì‚¬ìš©ìì˜ ê¸°ì €ì§ˆí™˜(ì°¸ê³ ìš©): {request.underlying_diseases} "f"í˜„ì¬ ë³µìš© ì¤‘ì¸ ì•½ë¬¼(ì°¸ê³ ìš©): {request.current_medications}")

        loop = asyncio.get_event_loop()
        user_id = "default"
        
        # íŒŒì¼ IDê°€ ìˆìœ¼ë©´ ìºì‹œëœ watsonx vision ê²°ê³¼ ë¨¼ì € í™•ì¸
        if request.file_id:
            try:
                print(f"[INFO] íŒŒì¼ ì²˜ë¦¬ ì‹œì‘ - {request.file_id}")
                
                # ğŸ”§ ìºì‹œì—ì„œ ì´ë¯¸ ì²˜ë¦¬ëœ ê²°ê³¼ í™•ì¸ (í•¨ìˆ˜ ì‚¬ìš©)
                cached_result = get_vision_result(request.file_id)
                
                if cached_result and cached_result.get("success"):
                    print(f"[INFO] ìºì‹œëœ watsonx vision ê²°ê³¼ ì‚¬ìš©")
                    
                    # ìºì‹œëœ í…ìŠ¤íŠ¸ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ê²°í•©
                    combined_prompt = f"""ë‹¤ìŒì€ watsonx visionìœ¼ë¡œ ë¶„ì„í•œ ì˜ë£Œ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:

                                        === ë¶„ì„ëœ ë‚´ìš© ===
                                        {cached_result["text"]}

                                        === ì‚¬ìš©ì ì§ˆë¬¸ ===
                                        {request.question}

                                        ìœ„ ì˜ë£Œ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì „ë¬¸ì ì´ê³  ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

                    # ê¸°ì¡´ í…ìŠ¤íŠ¸ LLMìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
                    final_answer = await loop.run_in_executor(None, call_llm, combined_prompt)
                    
                    return {
                        "answer": final_answer,
                        "user_context": {
                            "underlying_diseases": request.underlying_diseases or [],
                            "medications": request.current_medications or []
                        },
                        "model_metadata": {
                            "llm_classification": "cached_watsonx_vision",
                            "agent_used": "Cached watsonx Vision + LLM",
                            "model_name": "watsonx Vision + IBM Watson",
                            "status": "success"
                        },
                        "status": "success"
                    }
                else:
                    print(f"[INFO] ìºì‹œì— ê²°ê³¼ ì—†ìŒ, ìƒˆë¡œ ì²˜ë¦¬")
                
                # ìºì‹œì— ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš° ìƒˆë¡œ ì²˜ë¦¬
                medical_prompt = f"""ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ Dr. Watsonì…ë‹ˆë‹¤.

                                    ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

                                    ì‚¬ìš©ì ì§ˆë¬¸: {request.question}

                                    ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:
                                    - ë¬¸ì„œ ì¢…ë¥˜ (ì²˜ë°©ì „, ì•½í’ˆ ë¼ë²¨, ê²€ì‚¬ê²°ê³¼ ë“±)
                                    - ì£¼ìš” ì˜ë£Œ ì •ë³´ (ì•½ë¬¼ëª…, ìš©ëŸ‰, ë³µìš©ë²• ë“±)
                                    - ì£¼ì˜ì‚¬í•­ì´ë‚˜ íŠ¹ì´ì‚¬í•­
                                    - ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë‹µë³€

                                    ì¤‘ë³µë˜ëŠ” ë‚´ìš© ì—†ì´ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

                # ğŸ†• watsonx vision ì²˜ë¦¬
                watsonx_result = await loop.run_in_executor(
                    None, process_image_with_watsonx_vision, request.file_id, medical_prompt
                )
                
                # ğŸ†• ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (ì¤‘ìš”!)
                set_vision_result(request.file_id, {
                    "success": True,
                    "text": watsonx_result,
                    "method": "fresh_watsonx_vision"
                })
                
                return {
                    "answer": watsonx_result,
                    "user_context": {
                        "underlying_diseases": request.underlying_diseases or [],
                        "medications": request.current_medications or []
                    },
                    "model_metadata": {
                        "llm_classification": "fresh_watsonx_vision",
                        "agent_used": "Fresh watsonx Vision",
                        "model_name": "watsonx Vision",
                        "status": "success"
                    },
                    "status": "success"
                }
                
            except Exception as watsonx_error:
                print(f"[ERROR] watsonx Vision ì²˜ë¦¬ ì‹¤íŒ¨: {str(watsonx_error)}")
                
                # ğŸ†• ì‹¤íŒ¨í•œ ê²°ê³¼ë„ ìºì‹œì— ì €ì¥ (ì¬ì‹œë„ ë°©ì§€)
                set_vision_result(request.file_id, {
                    "success": False,
                    "text": "",
                    "error": str(watsonx_error),
                    "method": "failed_watsonx_vision"
                })
                
                return {
                    "answer": f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(watsonx_error)}",
                    "status": "error"
                }
     
       
        # ìº˜ë¦°ë” í™•ì¸ ì‘ë‹µ ëŒ€ê¸° ì¤‘ì¸ì§€ ì²´í¬
        if user_id in _user_sessions and _user_sessions[user_id].get('waiting_calendar_confirmation'):
            print(f"[INFO] ìº˜ë¦°ë” í™•ì¸ ì‘ë‹µ ì²˜ë¦¬ ì¤‘: {request.question}")

            _, _, calendar_ai = get_specialized_agents()
            
            # ì‚¬ìš©ìê°€ ê¸ì •ì ìœ¼ë¡œ ë‹µí–ˆëŠ”ì§€ í™•ì¸
            if calendar_ai.check_confirmation(request.question):
                # ìº˜ë¦°ë”ì— ì¶”ê°€ ì§„í–‰
                original_text = _user_sessions[user_id]['original_medication_text']
                result = await loop.run_in_executor(
                    None, calendar_ai.process_calendar_addition, user_id, original_text
                )
                
                if result['success']:
                    ai_response = f"âœ… ì„±ê³µì ìœ¼ë¡œ ìº˜ë¦°ë”ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!"
                else:
                    ai_response = f"âŒ ìº˜ë¦°ë” ì¶”ê°€ ì‹¤íŒ¨"
                
                agent_used = "CalendarAI-Step2"
            else:
                # ê±°ë¶€ ì‘ë‹µ
                ai_response = "ì•Œê² ìŠµë‹ˆë‹¤. ìº˜ë¦°ë” ì¶”ê°€ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
                agent_used = "CalendarAI-Cancelled"
            
            # ì„¸ì…˜ ì •ë¦¬
            del _user_sessions[user_id]
            
            return {
                "answer": ai_response.strip(),
                "user_context": {
                    "underlying_diseases": request.underlying_diseases or [],
                    "medications": request.current_medications or []
                },
                "model_metadata": {
                    "llm_classification": "calendar_confirmation",
                    "agent_used": agent_used,
                    "model_name": "IBM Watson (Calendar Processing)",
                    "status": "success"
                },
                "status": "success"
            }
        
        # ì¼ë°˜ì ì¸ LLM ë¶„ë¥˜ ì²˜ë¦¬
        request.question = (f"{request.question} " f"ì‚¬ìš©ìì˜ ê¸°ì €ì§ˆí™˜(ì°¸ê³ ìš©): {request.underlying_diseases} "f"í˜„ì¬ ë³µìš© ì¤‘ì¸ ì•½ë¬¼(ì°¸ê³ ìš©): {request.current_medications}")


        llm_response = await loop.run_in_executor(None, call_llm, request.question)

        print(f"[INFO] LLM ì‘ë‹µ: {llm_response}")
        
        if llm_response == "warn":
            # WarnAI í˜¸ì¶œ
            _, warn_ai, _ = get_specialized_agents()
            ai_response = await loop.run_in_executor(None, warn_ai.get_drug_warnings, request.question)
            agent_used = "WarnAI"
            
        elif llm_response == "explain":
            # ExplainAI í˜¸ì¶œ
            explain_ai, _, _ = get_specialized_agents()
            ai_response = await loop.run_in_executor(None, explain_ai.explain_drug, request.question)
            agent_used = "ExplainAI"
            
        elif llm_response == "add_cal":
            # CalendarAI 1ë‹¨ê³„: ë¶„ì„í•˜ê³  í™•ì¸ ìš”ì²­
            _, _, calendar_ai = get_specialized_agents()
            ai_response = await loop.run_in_executor(
                None, calendar_ai.analyze_medication_schedule, request.question
            )
            agent_used = "CalendarAI-Step1"
            
            # ì„¸ì…˜ì— ì €ì¥í•´ì„œ ë‹¤ìŒ ì‘ë‹µ ê¸°ë‹¤ë¦¬ê¸°
            _user_sessions[user_id] = {
                'waiting_calendar_confirmation': True,
                'original_medication_text': request.question
            }
            print(f"[INFO] ìº˜ë¦°ë” í™•ì¸ ëŒ€ê¸° ì„¸ì…˜ ìƒì„±: {user_id}")
            
        else:
            # ì¼ë°˜ ëŒ€í™” - LLM ì‘ë‹µ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            ai_response = llm_response
            agent_used = "MainChat"
        
        return {
            "answer": ai_response.strip(),
            "user_context": {
                "underlying_diseases": request.underlying_diseases or [],
                "medications": request.current_medications or []
            },
            "model_metadata": {
                "llm_classification": llm_response,
                "agent_used": agent_used,
                "model_name": "IBM Watson (Simple Direct API)",
                "status": "success"
            },
            "status": "success"
        }
        
    except Exception as e:
        print(f"[ERROR] ì±„íŒ… ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return await _get_fallback_response(request, str(e))


async def _get_fallback_response(request: ChatRequest, error_msg: str):
    """ì—ëŸ¬ ë°œìƒì‹œ fallback ì‘ë‹µ"""
    user_context = []
    if request.underlying_diseases:
        user_context.append(f"ê¸°ì €ì§ˆí™˜: {', '.join(request.underlying_diseases)}")
    if request.current_medications:
        user_context.append(f"ë³µìš©ì•½ë¬¼: {', '.join(request.current_medications)}")

    context_text = " | ".join(user_context) if user_context else "ì—†ìŒ"

    fallback_response = f"""ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ìƒë‹´ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ì˜¤ë¥˜: {error_msg}

ê·€í•˜ì˜ ì§ˆë¬¸: "{request.question}"
ì‚¬ìš©ì ì •ë³´: {context_text}."""

    return {
        "answer": fallback_response,
        "user_context": {
            "underlying_diseases": request.underlying_diseases or [],
            "medications": request.current_medications or []
        },
        "status": "fallback",
        "error": error_msg
    }

@router.get("/health", summary="ì±„íŒ… ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸")
async def health_check():
    """IBM Watson ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""

    config_status = {
        "WATSONX_API_KEY": bool(settings.WATSONX_API_KEY),
        "WATSONX_DEPLOYMENT_URL": bool(getattr(settings, 'WATSONX_DEPLOYMENT_URL', True))
    }

    watson_status = "unknown"
    watson_error = None

    try:
        token = get_watson_token()
        if token:
            watson_status = "healthy"
        else:
            watson_status = "unavailable"
            watson_error = "Token generation failed"
    except Exception as e:
        watson_status = "error"
        watson_error = str(e)

    agents_status = {}
    try:
        explain_ai, warn_ai, calendar_ai = get_specialized_agents()
        agents_status = {
            "ExplainAI": "healthy" if explain_ai else "unavailable",
            "WarnAI": "healthy" if warn_ai else "unavailable",
            "CalendarAI": "healthy" if calendar_ai else "unavailable"
        }
    except Exception as e:
        agents_status = {
            "error": f"ì „ë¬¸ AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
        }

    all_configured = bool(settings.WATSONX_API_KEY)
    overall_status = "healthy" if watson_status == "healthy" and all_configured else "degraded"

    return {
        "service": "Dr.Watson Chat API (Calendar 2-Step)",
        "status": overall_status,
        "config_status": config_status,
        "watson_api_status": watson_status,
        "watson_error": watson_error,
        "specialized_agents_status": agents_status,
        "active_sessions": len(_user_sessions),
        "all_configured": all_configured,
        "api_method": "Direct requests API with Calendar 2-step process",
        "architecture": "LLM Classification + Specialized Agents + Calendar Session",
        "message": "ìº˜ë¦°ë” 2ë‹¨ê³„ ì²˜ë¦¬ê°€ í¬í•¨ëœ ê°„ë‹¨í•œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤." if overall_status == "healthy" else "ì‹œìŠ¤í…œ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”."
    }