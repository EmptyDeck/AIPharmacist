# import logging
# from typing import Optional

# from fastapi import APIRouter
# from pydantic import BaseModel
# from ibm_watson_machine_learning.foundation_models import Model
# from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams
# from core.config import settings

# router = APIRouter()

# # ëª¨ë¸ ì¸ì¦ ì •ë³´ ë° ì´ˆê¸°í™”
# creds = {
#     "url": settings.WATSONX_API_URL,
#     "apikey": settings.WATSONX_API_KEY
# }

# try:
#     model = Model(
#         model_id='ibm/granite-3-3-8b-instruct',
#         credentials=creds,
#         project_id=settings.WATSONX_PROJECT_ID
#     )
# except Exception as e:
#     logging.error(f"ğŸ›‘ IBM ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
#     raise e

# def get_completion(prompt: str, max_tokens: int = 200, temperature: float = 0.7) -> str:
#     try:
#         response = model.generate(
#             prompt=prompt,
#             params={
#                 GenParams.MAX_NEW_TOKENS: 100,
#                 GenParams.TEMPERATURE: temperature
#             }
#         )
#         return response['results'][0]['generated_text']
#     except Exception as e:
#         logging.error(f"ğŸ›‘ GPT ì‘ë‹µ ì˜¤ë¥˜: {e}")
#         return "âš ï¸ GPT ì‘ë‹µì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# class GPTRequest(BaseModel):
#     message: str

# @router.post("/audio/gpt")
# async def gpt_response(request: GPTRequest):
#     prompt = f"""
#     ë‹¹ì‹ ì€ 'ë‹¥í„°ì™“ìŠ¨'ì´ë¼ëŠ” ì‚¬ëŒì˜ ì•½êµ­ ì˜ì‚¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ë©”ì„¸ì§€ì— ëŒ€í•´ì„œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
#     ê·¸ë¦¬ê³  ë‹µë³€ì€ 3ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
#     ì‚¬ìš©ìì˜ ì…ë ¥ì€ ì´ìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì‚¬ìš©ìëŠ” STTë¥¼ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— ë§Œì•½ ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì´ìƒí•˜ë‹¤ë©´ ëˆˆì¹˜ë¡œ ì´í•´í•´ì£¼ì„¸ìš”.
#     ``````
#     """
#     response_text = get_completion(prompt)
#     return {"text": response_text}


# #backend/api/audio/gpt.py
# import logging
# import os
# from typing import Optional

# from fastapi import APIRouter
# from pydantic import BaseModel
# from core.config import settings

# # Gemini Python SDK import
# from google import genai

# router = APIRouter()

# # GEMINI_API_KEYë¥¼ í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡
# os.environ["GEMINI_API_KEY"] = settings.GEMINI_API_KEY

# # Gemini client ê°ì²´ ìƒì„± (í™˜ê²½ë³€ìˆ˜ ìë™ ì¸ì‹)
# client = genai.Client()

# def get_completion(prompt: str, max_tokens: int = 200, temperature: float = 0.7) -> str:
#     try:
#         response = client.models.generate_content(
#             model="gemini-2.0-flash-001",
#             contents=prompt
#         )

#         return response.text
#     except Exception as e:
#         logging.error(f"ğŸ›‘ gpt.py ì‘ë‹µ ì˜¤ë¥˜: {e}")
#         return "âš ï¸ gpt.py ì‘ë‹µì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."


# class GPTRequest(BaseModel):
#     message: str

# @router.post("/audio/gpt")
# async def gpt_response(request: GPTRequest):
#     prompt = (
#         "ë„ˆëŠ” ì´ë¦„ì´ 'ë‹¥í„°ì™“ìŠ¨'ì¸ í•œêµ­ì¸ ì•½ì‚¬ ì±—ë´‡ì´ì•¼"
#         "ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ êµ¬ì–´ì²´ë¡œ ì§§ê²Œ ëŒ€ë‹µí•´ì¤˜"
#         "ìµœëŒ€ 2ë¬¸ì¥ ì´ë‚´, ì ˆëŒ€ ëª©ë¡Â·ë‚˜ì—´Â·ì¥ë¬¸ í”¼í•´"
#         "ìƒëŒ€ê°€ ìŒì„±ìœ¼ë¡œ ë§í•˜ë“¯ ë¬¼ì–´ë³´ë©´, ê·¸ê²ƒì„ ë“£ê³  ì¼ìƒëŒ€í™”í•˜ë“¯ ë‹µë³€í•´ì¤˜. "
#         "ì–´ë–¤ ì£¼ì œë“  ì•½êµ­ ì•½ì‚¬ í†¤ì„ ë²—ì–´ë‚˜ì§€ ë§ê³ , ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì–´ìƒ‰í•˜ê±°ë‚˜ ë¶ˆë¶„ëª…í•´ë„, ë§¥ë½ìƒ ê°€ì¥ ì¢‹ì€ ì•ˆë‚´ë¥¼ ì ê¹(ìµœëŒ€ 2ë¬¸ì¥) í•´ì¤˜. "
#         "ë°˜ë“œì‹œ ì¡´ëŒ“ë§ì„ ìœ ì§€í•´ì¤˜"
#         "ì‚¬ìš©ìëŠ” STTë¥¼ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— ë§Œì•½ ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì´ìƒí•˜ë‹¤ë©´ ìµœëŒ€í•œ ì˜ ì˜ˆì¸¡í•´ì¤˜." \
#         "ì½¤ë§ˆ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì‚¬ìš©í•´ì•¼í•˜ë©´ ê¼­ ë„ì–´ì“°ê¸°ë¡œ í•´ì¤˜"
#         "ì´ëª¨í‹°ì½˜ ì ì§€ë§ˆ"
#         f"{request.message}"
#     )
#     response_text = get_completion(prompt)
#     return {"text": response_text}


# + cal

# backend/api/audio/gpt.py
import logging
import os
import asyncio
from typing import Dict

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from core.config import settings

# Google-Gemini SDK
from google import genai

# ìº˜ë¦°ë”ìš© AI & ì—ì´ì „íŠ¸
from api.chatbot.calendarAI import calendar_ai       # ë¶„ì„Â·ì¶”ê°€ ë‹´ë‹¹

router = APIRouter()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini ì´ˆê¸°í™” (ì½”ë“œ2ì™€ ë™ì¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ["GEMINI_API_KEY"] = settings.GEMINI_API_KEY
client = genai.Client()
MODEL_ID = "gemini-2.0-flash-001"


def gemini_completion(prompt: str) -> str:
    try:
        resp = client.models.generate_content(model=MODEL_ID, contents=prompt)
        return resp.text.strip()
    except Exception as e:
        logging.error(f"ğŸ›‘ Gemini í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="Gemini í˜¸ì¶œ ì‹¤íŒ¨")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ì‚¬ìš©ì ì„¸ì…˜ (ìº˜ë¦°ë” í™•ì¸ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# key = speaker_id (ì§€ê¸ˆì€ 'voice_user' ê³ ì •)
_user_sessions: Dict[str, Dict] = {}


class VoiceRequest(BaseModel):
    message: str
    speaker_id: str | None = None   # í•„ìš”í•˜ë©´ ëª¨ë°”ì¼ UUID ë“±


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ë©”ì¸ ë¼ìš°í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.post("/audio/gpt")
async def voice_chat(req: VoiceRequest):

    user_id = req.speaker_id or "voice_user"     # ê°„ë‹¨íˆ ê³ ì •

    # â‘  ì´ë¯¸ 'ì¶”ê°€í• ê¹Œìš”?' ì§ˆë¬¸ ë’¤ ì‘ë‹µ ë‹¨ê³„ì¸ì§€?
    if user_id in _user_sessions and _user_sessions[user_id]["waiting_confirm"]:
        if calendar_ai.check_confirmation(req.message):
            # ê¸ì • â†’ ìº˜ë¦°ë” ì‹¤ì œ ì¶”ê°€
            original = _user_sessions[user_id]["original_text"]
            result = await asyncio.get_event_loop().run_in_executor(
                None, calendar_ai.process_calendar_addition, original
            )

            del _user_sessions[user_id]          # ì„¸ì…˜ ì •ë¦¬

            if result.get("success"):
                return {"text": "ìº˜ë¦°ë”ì— ì„±ê³µì ìœ¼ë¡œ ë“±ë¡í–ˆì–´ìš”."}
            return {"text": "ì¼ì •ì„ ì¶”ê°€í•˜ì§€ ëª»í–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."}

        else:
            # ë¶€ì • ë˜ëŠ” ê¸°íƒ€ â†’ ì·¨ì†Œ
            del _user_sessions[user_id]
            return {"text": "ë„¤ ì•Œê² ìŠµë‹ˆë‹¤. ìº˜ë¦°ë”ì—ëŠ” ì¶”ê°€í•˜ì§€ ì•Šì„ê²Œìš”."}

    # ---------------------------------------------
    # â‘¡ ë³µì•½ ì¼ì • ì˜ë„ ê°ì§€ â†’ â€˜ìš”ì•½+ì§ˆë¬¸â€™ ë‹¨ê³„
    # ---------------------------------------------
    lowered = req.message.lower()
    drug_keywords = ["ìº˜ë¦°ë”", "ì¼ì •", "ì•ŒëŒ", "êµ¬ê¸€"]

    # drug í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ ìˆê³  ì•„ì§ í™•ì¸ ì„¸ì…˜ì´ ì—†ìœ¼ë©´ â†’ ì¼ì • ë¶„ì„
    if any(k in lowered for k in drug_keywords) and user_id not in _user_sessions:
        # 1) (ì´ë²¤íŠ¸ ìƒì„±ìš©) CalendarAI ë‚´ë¶€ ë¶„ì„ í˜¸ì¶œ  â”€ ì‚­ì œí•´ë„ ë¬´ë°©
        await asyncio.get_event_loop().run_in_executor(
            None, calendar_ai.analyze_medication_schedule, req.message
        )

        # 2) ìŒì„±ìš© â€˜ìš”ì•½ + ë“±ë¡ ì—¬ë¶€â€™ ë¬¸ì¥ Geminië¡œ ìƒì„±
        summary_prompt = (
            "ë„ˆëŠ” í•œêµ­ì¸ ì•½ì‚¬ ì±—ë´‡ì´ë‹¤. ì‚¬ìš©ìì˜ ë³µì•½ ì§€ì‹œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•œ ë’¤ "
            "ë§ˆì§€ë§‰ì— â€˜ì´ ì¼ì •ì„ êµ¬ê¸€ ìº˜ë¦°ë”ì— ë“±ë¡í•´ ë“œë¦´ê¹Œìš”?â€™ ë¥¼ ë¶™ì—¬ë¼. "
            "ë§Œì•½, 'ì•½ì´ë¦„, ë³µìš©ì‹œê°„, ëª‡ì¼ê°„ ë¨¹ëŠ”ì§€ê°€ ëª…í™•í•˜ì§€ ì•Šë‹¤ë©´, ëª…í™•íˆ ì•Œë ¤ë‹¬ë¼ê³  ìš”ì²­í• ê²ƒ"
            "ì¡´ëŒ“ë§ êµ¬ì–´ì²´, 120ì ì´í•˜, ëª©ë¡Â·íŠ¹ìˆ˜ê¸°í˜¸Â·ì´ëª¨í‹°ì½˜ ê¸ˆì§€.\n\n"
            f"ë³µì•½ ì§€ì‹œ: {req.message}"
        )
        voice_answer = gemini_completion(summary_prompt)

        # 3) ì„¸ì…˜ ì €ì¥ â†’ ë‹¤ìŒ í„´ì—ì„œ Yes/No íŒë³„
        _user_sessions[user_id] = {
            "waiting_confirm": True,
            "original_text":   req.message
        }
        return {"text": voice_answer}   # ê¸¸ì´ ì œí•œ

    # â‘¢ ì¼ë°˜ ëŒ€í™” â†’ Gemini ì§§ì€ ë‹µ
    prompt = (
        "ë„ˆëŠ” ì´ë¦„ì´ 'ë‹¥í„°ì™“ìŠ¨'ì¸ í•œêµ­ì¸ ì•½ì‚¬ ì±—ë´‡ì´ì•¼"
        "ë„ˆëŠ” ë³µì•½ ìƒë‹´ê³¼ ì•½ì—ëŒ€í•œ ê¶ê¸ˆì¦ì„ í•´ê²°í• ìˆ˜ ìˆê³ , ì•½ì— ëŒ€í•œ ì¼ì •ì„ ìº˜ë¦°ë”ì— ì¶”ê°€í•  ìˆ˜ ìˆì–´"
        "ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ êµ¬ì–´ì²´ë¡œ ì§§ê²Œ ëŒ€ë‹µí•´ì¤˜"
        "ìµœëŒ€ 2ë¬¸ì¥ ì´ë‚´, ì ˆëŒ€ ëª©ë¡Â·ë‚˜ì—´Â·ì¥ë¬¸ í”¼í•´"
        "ìƒëŒ€ê°€ ìŒì„±ìœ¼ë¡œ ë§í•˜ë“¯ ë¬¼ì–´ë³´ë©´, ê·¸ê²ƒì„ ë“£ê³  ì¼ìƒëŒ€í™”í•˜ë“¯ ë‹µë³€í•´ì¤˜. "
        "ì–´ë–¤ ì£¼ì œë“  ì•½êµ­ ì•½ì‚¬ í†¤ì„ ë²—ì–´ë‚˜ì§€ ë§ê³ , ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì–´ìƒ‰í•˜ê±°ë‚˜ ë¶ˆë¶„ëª…í•´ë„, ë§¥ë½ìƒ ê°€ì¥ ì¢‹ì€ ì•ˆë‚´ë¥¼ ì ê¹(ìµœëŒ€ 2ë¬¸ì¥) í•´ì¤˜. "
        "ë°˜ë“œì‹œ ì¡´ëŒ“ë§ì„ ìœ ì§€í•´ì¤˜"
        "ì‚¬ìš©ìëŠ” STTë¥¼ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— ë§Œì•½ ì‚¬ìš©ìì˜ ì…ë ¥ì´ ì´ìƒí•˜ë‹¤ë©´ ìµœëŒ€í•œ ì˜ ì˜ˆì¸¡í•´ì¤˜."
        "ì½¤ë§ˆ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì‚¬ìš©í•´ì•¼í•˜ë©´ ê¼­ ë„ì–´ì“°ê¸°ë¡œ í•´ì¤˜"
        "ì´ëª¨í‹°ì½˜,íŠ¹ìˆ˜ê¸°í˜¸ ì“°ì§€ë§ˆ"
        f"{req.message}"
    )
    answer = gemini_completion(prompt)
    return {"text": answer}
